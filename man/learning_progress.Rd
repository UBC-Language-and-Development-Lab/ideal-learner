% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/learning_progress.R
\name{learning_progress}
\alias{learning_progress}
\title{Compute Learning Progress}
\usage{
learning_progress(x)
}
\arguments{
\item{x}{a \code{factor} representing an observed sequence.}
}
\value{
Estimate of learning progress
}
\description{
Learning progress is quantified in terms of Kullback-Leibler Divergence
(or information gain), \eqn{D_{KL}}:

\eqn{D_{KL}=(p^j|p^{j-1}) \sum_{k=1}^{K}p(x^j=k|X^j, \alpha)\log_{2}\frac{p(x^j=k|X^j,\alpha)}{p(x^j=k|X^{j-1}, \alpha)}}

\eqn{D_{KL}} is the divergence between a weighted average of prediction error
at trial j and a weighted average of prediction error at trial j âˆ’ 1, and
hence, it is a suitable way to model learning progress (Poli et al, 2020)
}
\examples{
learning_progress(factor(c(1), levels = 1:3))
}
\seealso{
\code{\link[=prob_target]{prob_target()}}, \code{\link[=prob_target1]{prob_target1()}}
}
